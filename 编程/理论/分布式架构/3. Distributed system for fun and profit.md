# 1. Distributed systems at a high level
There are two basic tasks that any computer system needs to accomplish:
- storage and
- computation
> 任何计算机系统都需要完成两项基本任务：存储和计算。

Distributed programming is the art of solving the same problem that you can solve on a single computer using multiple computers - usually, because the problem no longer fits on a single computer.
> 分布式编程是用多台计算机解决在单台计算机上可以解决的同一问题的艺术--通常是因为该问题不再适合在单台计算机上解决。

However, as problem sizes increase you will reach a point where either the hardware upgrade that allows you to solve the problem on a single node does not exist, or becomes cost-prohibitive. At that point, I welcome you to the world of distributed systems.
> 但是，随着问题规模的增大，你将会遇到这样的情况：要么无法升级硬件，让你在单个节点上解决问题，要么成本过高。这时，我欢迎你来到分布式系统的世界。

It is a current reality that the best value is in mid-range, commodity hardware - as long as the maintenance costs can be kept down through fault-tolerant software.
> 目前的现实情况是，只要能通过容错软件降低维护成本，中端商品硬件的价值最高。

Ideally, adding a new machine would increase the performance and capacity of the system linearly. But of course this is not possible, because there is some overhead that arises due to having separate computers. Data needs to be copied around, computation tasks have to be coordinated and so on. This is why it's worthwhile to study distributed algorithms - they provide efficient solutions to specific problems, as well as guidance about what is possible, what the minimum cost of a correct implementation is, and what is impossible.
> 在理想情况下，增加一台新机器可以线性地提高系统的性能和容量。但这当然是不可能的，因为拥有独立的计算机会产生一些开销。数据需要复制，计算任务需要协调等等。这就是为什么值得研究分布式算法的原因--它们为特定问题提供了高效的解决方案，并指导我们了解哪些是可能的，正确实现的最低成本是多少，以及哪些是不可能的。

## What we want to achieve: Scalability and other good things
[Scalability](http://en.wikipedia.org/wiki/Scalability)：is the ability of a system, network, or process, to handle a growing amount of work in a capable manner or its ability to be enlarged to accommodate that growth.
> 可扩展性：是指一个系统、网络或流程能够以适当的方式处理不断增长的工作量，或能够扩大以适应这种增长的能力。

- Size scalability: adding more nodes should make the system linearly faster; growing the dataset should not increase latency
- Geographic scalability: it should be possible to use multiple data centers to reduce the time it takes to respond to user queries, while dealing with cross-data center latency in some sensible manner.
- Administrative scalability: adding more nodes should not increase the administrative costs of the system (e.g. the administrators-to-machines ratio).
> 
	规模可扩展性：增加节点应使系统的速度呈线性增长；数据集的增长不应增加延迟
	地理可扩展性：应该可以使用多个数据中心来减少响应用户查询所需的时间，同时以某种合理的方式处理跨数据中心的延迟。
	管理可扩展性：增加节点不应增加系统的管理成本（如管理员与机器之比）。

A scalable system is one that continues to meet the needs of its users as scale increases. There are two particularly relevant aspects - performance and availability - which can be measured in various ways.
>可扩展系统是指随着规模的扩大，仍能满足用户需求的系统。有两个特别相关的方面--性能和可用性--可以通过各种方式来衡量。

### Performance (and latency)
[Performance](http://en.wikipedia.org/wiki/Computer_performance): is characterized by the amount of useful work accomplished by a computer system compared to the time and resources used.
> 性能：是指计算机系统完成的有用工作与所用时间和资源的比较。

Depending on the context, this may involve achieving one or more of the following:
- Short response time/low latency for a given piece of work
- High throughput (rate of processing work)
- Low utilization of computing resource(s)
> 根据具体情况，这可能涉及实现以下一个或多个目标：
	特定工作的响应时间短/延迟低
	高吞吐量（处理工作的速度）
	计算资源利用率低

There are tradeoffs involved in optimizing for any of these outcomes. For example, a system may achieve a higher throughput by processing larger batches of work thereby reducing operation overhead. The tradeoff would be longer response times for individual pieces of work due to batching.
> 在对上述任何结果进行优化时，都需要权衡利弊。例如，系统可以通过处理更大批量的工作来获得更高的吞吐量，从而减少运行开销。但这样做的代价是，由于批量处理，单个工作的响应时间会更长。

Latency: The state of being latent; delay, a period between the initiation of something and the occurrence.
> 延迟：潜伏状态；延迟，某事开始和发生之间的一段时间。

Let's assume for a moment that our distributed system does just one high-level task: given a query, it takes all of the data in the system and calculates a single result. In other words, think of a distributed system as a data store with the ability to run a single deterministic computation (function) over its current content:
`result = query(all data in the system)`
> 让我们假设一下，我们的分布式系统只完成一项高级任务：给定一个查询，它获取系统中的所有数据并计算出一个结果。换句话说，可以把分布式系统看作是一个数据存储库，能够对其当前内容进行单次确定性计算（函数）：
	结果 = 查询（系统中的所有数据）

Then, what matters for latency is not the amount of old data, but rather the speed at which new data "takes effect" in the system. For example, latency could be measured in terms of how long it takes for a write to become visible to readers.
> 因此，对延迟而言，重要的不是旧数据的数量，而是新数据在系统中 "生效 "的速度。例如，延迟可以用写入到读者可见所需的时间来衡量。

In a distributed system, there is a minimum latency that cannot be overcome: the speed of light limits how fast information can travel, and hardware components have a minimum latency cost incurred per operation (think RAM and hard drives but also CPUs).
> 在分布式系统中，有一个无法逾越的最低延迟时间：光速限制了信息的传播速度，而硬件组件每次操作都会产生最低延迟成本（例如内存和硬盘，但也包括 CPU）。

How much that minimum latency impacts your queries depends on the nature of those queries and the physical distance the information needs to travel.
> 最小延迟对查询的影响程度取决于查询的性质和信息需要传输的物理距离。

### Availability (and fault tolerance)
[Availability](http://en.wikipedia.org/wiki/High_availability): the proportion of time a system is in a functioning condition. If a user cannot access the system, it is said to be unavailable.
> 可用性：系统处于正常运行状态的时间比例。如果用户无法访问系统，则称系统不可用。

Distributed systems allow us to achieve desirable characteristics that would be hard to accomplish on a single system. For example, a single machine cannot tolerate any failures since it either fails or doesn't.
> 分布式系统使我们能够实现单个系统难以实现的理想特性。例如，单台机器不能容忍任何故障，因为它要么故障，要么不故障。

Systems that have no redundancy can only be as available as their underlying components. Systems built with redundancy can be tolerant of partial failures and thus be more available. It is worth noting that "redundant" can mean different things depending on what you look at - components, servers, datacenters and so on.
> 没有冗余的系统只能像其基础组件一样可用。有冗余的系统可以承受部分故障，因此可用性更高。值得注意的是，"冗余 "可以有不同的含义，这取决于你关注的是什么--组件、服务器、数据中心等。

Formulaically, availability is: `Availability = uptime / (uptime + downtime)`.
> 按公式计算，可用性为可用性 = 正常运行时间/（正常运行时间 + 停机时间）。

Availability from a technical perspective is mostly about being fault tolerant. Because the probability of a failure occurring increases with the number of components, the system should be able to compensate so as to not become less reliable as the number of components increases.
> 从技术角度看，可用性主要是指容错性。由于发生故障的概率会随着组件数量的增加而增加，因此系统应该能够进行补偿，从而不会随着组件数量的增加而降低可靠性。

Availability is in some sense a much wider concept than uptime, since the availability of a service can also be affected by, say, a network outage or the company owning the service going out of business (which would be a factor which is not really relevant to fault tolerance but would still influence the availability of the system). But without knowing every single specific aspect of the system, the best we can do is design for fault tolerance.
> 在某种意义上，可用性是一个比正常运行时间更宽泛的概念，因为服务的可用性也会受到影响，例如网络中断或拥有服务的公司倒闭（这是一个与容错无关的因素，但仍会影响系统的可用性）。但在不了解系统每个具体方面的情况下，我们能做的就是设计容错。

Fault tolerance: ability of a system to behave in a well-defined manner once faults occur.
> 容错：系统在故障发生时以明确定义的方式运行的能力。

Fault tolerance boils down to this: define what faults you expect and then design a system or an algorithm that is tolerant of them. You can't tolerate faults you haven't considered.
> 容错归根结底就是：确定你所期望的故障，然后设计出能够容错的系统或算法。你不可能容忍你没有考虑到的故障。

## What prevents us from achieving good things?
Distributed systems are constrained by two physical factors:
- the number of nodes (which increases with the required storage and computation capacity)
- the distance between nodes (information travels, at best, at the speed of light)
> 分布式系统受到两个物理因素的制约：
	节点数量（随所需存储和计算能力的增加而增加）
	节点之间的距离（信息最多以光速传播）

Working within those constraints:
- an increase in the number of independent nodes increases the probability of failure in a system (reducing availability and increasing administrative costs)
- an increase in the number of independent nodes may increase the need for communication between nodes (reducing performance as scale increases)
- an increase in geographic distance increases the minimum latency for communication between distant nodes (reducing performance for certain operations)
> 在这些限制条件下开展工作：
	增加独立节点的数量会增加系统发生故障的概率（降低可用性并增加管理成本）
	独立节点数量的增加可能会增加节点之间的通信需求（随着规模的扩大而降低性能）
	地理距离的增加会增加远距离节点间通信的最小延迟（降低某些操作的性能）

Beyond these tendencies - which are a result of the physical constraints - is the world of system design options.
> 除了这些由物理限制之外，还有系统设计方案的限制。

Both performance and availability are defined by the external guarantees the system makes. On a high level, you can think of the guarantees as the SLA (service level agreement) for the system: if I write data, how quickly can I access it elsewhere? After the data is written, what guarantees do I have of durability? If I ask the system to run a computation, how quickly will it return results? When components fail, or are taken out of operation, what impact will this have on the system?
> 性能和可用性都是由系统的外部保证来定义的。从高层次上讲，可以将这些保证视为系统的 SLA（服务水平协议）：如果我写入数据，我在其他地方访问数据的速度有多快？数据写入后，我如何保证数据的持久性？如果我要求系统运行计算，它能多快返回结果？当组件发生故障或停止运行时，会对系统产生什么影响？

There is another criterion, which is not explicitly mentioned but implied: intelligibility. How understandable are the guarantees that are made? Of course, there are no simple metrics for what is intelligible.
> 还有一个标准没有明确提及，但隐含其中：可理解性。所做的保证有多容易理解？当然，什么是可理解性并没有简单的衡量标准。

## Abstractions and models
This is where abstractions and models come into play. Abstractions make things more manageable by removing real-world aspects that are not relevant to solving a problem. Models describe the key properties of a distributed system in a precise manner. I'll discuss many kinds of models in the next chapter, such as:
- System model (asynchronous / synchronous)
- Failure model (crash-fail, partitions, Byzantine)
- Consistency model (strong, eventual)
> 这就是抽象和模型发挥作用的地方。抽象可以去除现实世界中与解决问题无关的方面，从而使问题更易于管理。模型以精确的方式描述了分布式系统的关键属性。我将在下一章讨论多种模型，如
	系统模型（异步/同步）
	故障模型（崩溃-故障、分区、拜占庭）
	一致性模型（强一致性、最终一致性）

A good abstraction makes working with a system easier to understand, while capturing the factors that are relevant for a particular purpose.
> 一个好的抽象概念可以使系统的工作更容易理解，同时还能捕捉到与特定目的相关的因素。

## Design techniques: partition and replicate
The manner in which a data set is distributed between multiple nodes is very important. In order for any computation to happen, we need to locate the data and then act on it.
> 数据集在多个节点之间分布的方式非常重要。为了进行计算，我们需要找到数据，然后对其进行操作。

There are two basic techniques that can be applied to a data set. It can be split over multiple nodes (partitioning) to allow for more parallel processing. It can also be copied or cached on different nodes to reduce the distance between the client and the server and for greater fault tolerance (replication).
> 有两种基本技术可用于数据集。可以将数据分割到多个节点上（分区），以便进行更多并行处理。也可以在不同的节点上复制或缓存数据，以缩短客户端与服务器之间的距离，提高容错能力（复制）。

The picture below illustrates the difference between these two: partitioned data (A and B below) is divided into independent sets, while replicated data (C below) is copied to multiple locations.
> 下图说明了两者之间的区别：分区数据（下图中的 A 和 B）被划分为独立的数据集，而复制数据（下图中的 C）被复制到多个位置。
![[part-repl.png]]

This is the one-two punch for solving any problem where distributed computing plays a role. Of course, the trick is in picking the right technique for your concrete implementation; there are many algorithms that implement replication and partitioning, each with different limitations and advantages which need to be assessed against your design objectives.
> 这是解决任何涉及分布式计算问题的一记重拳。当然，诀窍在于为您的具体实现选择正确的技术；有许多实现复制和分区的算法，每种算法都有不同的局限性和优势，需要根据您的设计目标进行评估。

### Partitioning
Partitioning is dividing the dataset into smaller distinct independent sets; this is used to reduce the impact of dataset growth since each partition is a subset of the data.
- Partitioning improves performance by limiting the amount of data to be examined and by locating related data in the same partition
- Partitioning improves availability by allowing partitions to fail independently, increasing the number of nodes that need to fail before availability is sacrificed
> 分区是指将数据集划分为不同的独立小集；这用于减少数据集增长的影响，因为每个分区都是数据的一个子集。
	分区可以限制需要检查的数据量，并将相关数据定位在同一分区中，从而提高性能。
	分区允许分区独立发生故障，增加了在牺牲可用性之前需要发生故障的节点数量，从而提高了可用性

Partitioning is also very much application-specific, so it is hard to say much about it without knowing the specifics. That's why the focus is on replication in most texts, including this one.
> 分区在很大程度上也与具体应用有关，因此，在不了解具体情况的情况下，很难对其进行深入探讨。这就是为什么大多数文章（包括本文章）的重点都放在复制上。

### Replication
Replication is making copies of the same data on multiple machines; this allows more servers to take part in the computation.
> 复制是指在多台机器上复制相同的数据；这样可以让更多服务器参与计算。

Replication - copying or reproducing something - is the primary way in which we can fight latency.
- Replication improves performance by making additional computing power and bandwidth applicable to a new copy of the data
- Replication improves availability by creating additional copies of the data, increasing the number of nodes that need to fail before availability is sacrificed
> 复制 - 复制或复制某些东西 - 是我们对抗延迟的主要方式。
	复制通过使额外的计算能力和带宽适用于新的数据拷贝来提高性能
	复制通过创建额外的数据副本来提高可用性，从而增加在牺牲可用性之前需要失败的节点数

Replication is about providing extra bandwidth, and caching where it counts. It is also about maintaining consistency in some way according to some consistency model.
> 复制是为了提供额外的带宽，并在重要的地方进行缓存。此外，复制还需要根据某种一致性模型，以某种方式保持一致性。

Replication allows us to achieve scalability, performance and fault tolerance. Afraid of loss of availability or reduced performance? Replicate the data to avoid a bottleneck or single point of failure. Slow computation? Replicate the computation on multiple systems. Slow I/O? Replicate the data to a local cache to reduce latency or onto multiple machines to increase throughput.
> 复制使我们能够实现可扩展性、性能和容错。害怕丧失可用性或降低性能？复制数据以避免瓶颈或单点故障。计算速度慢？在多个系统上复制计算。I/O 速度慢？将数据复制到本地缓存以减少延迟，或复制到多台机器上以提高吞吐量。

Replication is also the source of many of the problems, since there are now independent copies of the data that has to be kept in sync on multiple machines - this means ensuring that the replication follows a consistency model.
> 复制也是许多问题的根源，因为现在有独立的数据副本，必须在多台机器上保持同步--这意味着要确保复制遵循一致性模型。

The choice of a consistency model is crucial: a good consistency model provides clean semantics for programmers (in other words, the properties it guarantees are easy to reason about) and meets business/design goals such as high availability or strong consistency.
> 一致性模型的选择至关重要：一个好的一致性模型能为程序员提供简洁的语义（换句话说，它所保证的属性易于推理），并能满足业务/设计目标，如高可用性或强一致性。

Only one consistency model for replication - strong consistency - allows you to program as-if the underlying data was not replicated. Other consistency models expose some internals of the replication to the programmer. However, weaker consistency models can provide lower latency and higher availability - and are not necessarily harder to understand, just different.
> 只有一种复制的一致性模型--强一致性--允许你在编程时假设底层数据没有被复制。其他一致性模型会向程序员暴露复制的一些内部信息。然而，较弱的一致性模型可以提供更低的延迟和更高的可用性，而且并不一定更难理解，只是不同而已。

# 2. Up and down the level of abstraction
## A system model
A key property of distributed systems is distribution. More specifically, programs in a distributed system:
- run concurrently on independent nodes ...
- are connected by a network that may introduce nondeterminism and message loss ...
- and have no shared memory or shared clock.
> 分布式系统的一个关键特性是分布。更具体地说，分布式系统中的程序：
	在独立节点上并发运行...
	由网络连接，可能引入非确定性和信息丢失...
	没有共享内存或共享时钟。

There are many implications:
- each node executes a program concurrently
- knowledge is local: nodes have fast access only to their local state, and any information about global state is potentially out of date
- nodes can fail and recover from failure independently
- messages can be delayed or lost (independent of node failure; it is not easy to distinguish network failure and node failure)
- and clocks are not synchronized across nodes (local timestamps do not correspond to the global real time order, which cannot be easily observed)
> 这有很多影响：
	每个节点同时执行一个程序
	知识是本地的：节点只能快速访问其本地状态，任何有关全局状态的信息都可能是过时的
	节点可以独立发生故障并从故障中恢复
	信息可能会延迟或丢失（与节点故障无关；不易区分网络故障和节点故障）
	节点间的时钟不同步（本地时间戳与全局实时顺序不一致，不易观察到）

A system model enumerates the many assumptions associated with a particular system design.
> 系统模型列举了与特定系统设计相关的许多假设。

System model: a set of assumptions about the environment and facilities on which a distributed system is implemented
> 系统模型：关于实施分布式系统的环境和设施的一系列假设

System models vary in their assumptions about the environment and facilities. These assumptions include:
- what capabilities the nodes have and how they may fail
- how communication links operate and how they may fail and
- properties of the overall system, such as assumptions about time and order
> 系统模型对环境和设施的假设各不相同。这些假设包括
	节点具有哪些能力，它们可能如何失效
	通信链路如何运行以及可能出现的故障
	整个系统的属性，如对时间和顺序的假设

A robust system model is one that makes the weakest assumptions: any algorithm written for such a system is very tolerant of different environments, since it makes very few and very weak assumptions.
> 稳健的系统模型是一种假设最弱的模型：为这种系统编写的任何算法都能很好地容忍不同的环境，因为它的假设非常少而且非常弱。

On the other hand, we can create a system model that is easy to reason about by making strong assumptions. For example, assuming that nodes do not fail means that our algorithm does not need to handle node failures. However, such a system model is unrealistic and hence hard to apply into practice.
> 另一方面，我们可以通过做出强有力的假设来创建一个易于推理的系统模型。例如，假设节点不会发生故障，就意味着我们的算法无需处理节点故障。然而，这样的系统模型是不现实的，因此很难应用到实践中。

### Nodes in our system model
Nodes serve as hosts for computation and storage. They have:
- the ability to execute a program
- the ability to store data into volatile memory (which can be lost upon failure) and into stable state (which can be read after a failure)
- a clock (which may or may not be assumed to be accurate)
> 节点是计算和存储的主机。它们具有
	执行程序的能力
	将数据存储到易失性存储器（故障时可能丢失）和稳定状态（故障后可读取）的能力
	时钟（可能准确，也可能不准确）

Nodes execute deterministic algorithms: the local computation, the local state after the computation, and the messages sent are determined uniquely by the message received and local state when the message was received.
> 节点执行确定性算法：本地计算、计算后的本地状态和发送的信息由收到的信息和收到信息时的本地状态唯一决定。

There are many possible failure models which describe the ways in which nodes can fail. In practice, most systems assume a crash-recovery failure model: that is, nodes can only fail by crashing, and can (possibly) recover after crashing at some later point.
> 有许多可能的故障模型可以描述节点可能发生故障的方式。在实践中，大多数系统都假设了崩溃-恢复故障模型：也就是说，节点只能通过崩溃来发生故障，并（可能）在崩溃后的某个时间点恢复。

Another alternative is to assume that nodes can fail by misbehaving in any arbitrary way. This is known as [Byzantine fault tolerance](http://en.wikipedia.org/wiki/Byzantine_fault_tolerance). Byzantine faults are rarely handled in real world commercial systems, because algorithms resilient to arbitrary faults are more expensive to run and more complex to implement. I will not discuss them here.
> 另一种方法是假定节点可能以任意方式行为不当而发生故障。这就是所谓的拜占庭容错。在现实世界的商业系统中，拜占庭故障很少得到处理，因为能够抵御任意故障的算法运行成本更高，实施起来也更复杂。在此，我将不作讨论。

### Communication links in our system model
Communication links connect individual nodes to each other, and allow messages to be sent in either direction. Many books that discuss distributed algorithms assume that there are individual links between each pair of nodes, that the links provide FIFO (first in, first out) order for messages, that they can only deliver messages that were sent, and that sent messages can be lost.
> 通信链路将单个节点相互连接起来，并允许向任一方向发送信息。许多讨论分布式算法的书籍都假定，每对节点之间都有单独的链路，链路为信息提供 FIFO（先进先出）顺序，链路只能传递已发送的信息，而且已发送的信息可能会丢失。

Some algorithms assume that the network is reliable: that messages are never lost and never delayed indefinitely. This may be a reasonable assumption for some real-world settings, but in general it is preferable to consider the network to be unreliable and subject to message loss and delays.
> 有些算法假设网络是可靠的：信息不会丢失，也不会无限期延迟。对于某些实际情况来说，这种假设可能是合理的，但一般来说，最好还是将网络视为不可靠的，会出现信息丢失和延迟。

A network partition occurs when the network fails while the nodes themselves remain operational. When this occurs, messages may be lost or delayed until the network partition is repaired. Partitioned nodes may be accessible by some clients, and so must be treated differently from crashed nodes. The diagram below illustrates a node failure vs. a network partition:
> 当网络发生故障，而节点本身仍可正常运行时，就会出现网络分区。发生这种情况时，信息可能会丢失或延迟，直到网络分区被修复。被分区的节点可能会被某些客户端访问，因此必须与崩溃的节点区别对待。下图展示了节点故障与网络分区的对比：
![[system-of-2.png]]

It is rare to make further assumptions about communication links. We could assume that links only work in one direction, or we could introduce different communication costs (e.g. latency due to physical distance) for different links. However, these are rarely concerns in commercial environments except for long-distance links (WAN latency) and so I will not discuss them here; a more detailed model of costs and topology allows for better optimization at the cost of complexity.
> 对通信链路做进一步的假设是很少见的。我们可以假设链路只在一个方向上工作，也可以为不同的链路引入不同的通信成本（如物理距离造成的延迟）。不过，除了长距离链接（广域网延迟）外，商业环境中很少涉及这些问题，因此我在此不作讨论；更详细的成本和拓扑模型可以在降低复杂性的同时实现更好的优化。

### Timing / ordering assumptions
One of the consequences of physical distribution is that each node experiences the world in a unique manner. This is inescapable, because information can only travel at the speed of light. If nodes are at different distances from each other, then any messages sent from one node to the others will arrive at a different time and potentially in a different order at the other nodes.
> 物理分布的后果之一是，每个节点都以独特的方式体验世界。这是不可避免的，因为信息只能以光速传播。如果节点之间的距离不同，那么从一个节点发送到其他节点的任何信息都会在不同的时间到达其他节点，并且可能以不同的顺序到达。

Timing assumptions are a convenient shorthand for capturing assumptions about the extent to which we take this reality into account. The two main alternatives are:
- Synchronous system model: Processes execute in lock-step; there is a known upper bound on message transmission delay; each process has an accurate clock
- Asynchronous system model: No timing assumptions - e.g. processes execute at independent rates; there is no bound on message transmission delay; useful clocks do not exist
> 时间假设是一种方便的简写，用来描述我们在多大程度上考虑到这一现实的假设。两种主要的选择是
	同步系统模型：进程同步执行；信息传输延迟有一个已知的上限；每个进程都有一个准确的时钟
	异步系统模型：没有时序假设--例如，进程以独立的速率执行；信息传输延迟没有上限；不存在有用的时钟

The synchronous system model imposes many constraints on time and order. It essentially assumes that the nodes have the same experience: that messages that are sent are always received within a particular maximum transmission delay, and that processes execute in lock-step. This is convenient, because it allows you as the system designer to make assumptions about time and order, while the asynchronous system model doesn't.
> 同步系统模型对时间和顺序施加了许多限制。它基本上假定节点具有相同的经验：发送的信息总是在特定的最大传输延迟内收到，并且进程按部就班地执行。这很方便，因为它允许系统设计者对时间和顺序做出假设，而异步系统模型则不允许。

Asynchronicity is a non-assumption: it just assumes that you can't rely on timing (or a "time sensor").
> 异步性是一个非假设：它只是假设你不能依赖计时（或“时间传感器”）。

It is easier to solve problems in the synchronous system model, because assumptions about execution speeds, maximum message transmission delays and clock accuracy all help in solving problems since you can make inferences based on those assumptions and rule out inconvenient failure scenarios by assuming they never occur.
> 在同步系统模型中更容易解决问题，因为对执行速度、最大信息传输延迟和时钟精度的假设都有助于解决问题，因为你可以根据这些假设做出推断，并通过假设它们永远不会发生来排除不方便的故障情况。

Of course, assuming the synchronous system model is not particularly realistic. Real-world networks are subject to failures and there are no hard bounds on message delay. Real world systems are at best partially synchronous: they may occasionally work correctly and provide some upper bounds, but there will be times where messages are delayed indefinitely and clocks are out of sync. I won't really discuss algorithms for synchronous systems here, but you will probably run into them in many other introductory books because they are analytically easier (but unrealistic).
> 当然，假设同步系统模型并不特别现实。现实世界的网络可能会出现故障，而且信息延迟也没有硬约束。现实世界中的系统充其量只是部分同步：它们偶尔会正常工作并提供一些上限，但有时也会出现信息无限期延迟和时钟不同步的情况。我不会在这里讨论同步系统的算法，但你可能会在许多其他入门书籍中看到它们，因为它们在分析上更容易（但不现实）。

### The consensus problem 共识问题
Several computers (or nodes) achieve consensus if they all agree on some value. More formally:
1. Agreement: Every correct process must agree on the same value.
2. Integrity: Every correct process decides at most one value, and if it decides some value, then it must have been proposed by some process.
3. Termination: All processes eventually reach a decision.
4. Validity: If all correct processes propose the same value V, then all correct processes decide V.
> 如果多台计算机（或节点）都同意某个值，就能达成共识。更正式的说法是
	协议：每个正确的进程都必须就相同的值达成一致。
	完整性：每个正确的进程最多决定一个值，如果它决定了某个值，那么它一定是由某个进程提出的。
	终止：所有进程最终都会做出决定。
	有效性：如果所有正确的进程都提出了相同的值 V，那么所有正确的进程都会决定 V。

The consensus problem is at the core of many commercial distributed systems. After all, we want the reliability and performance of a distributed system without having to deal with the consequences of distribution (e.g. disagreements / divergence between nodes), and solving the consensus problem makes it possible to solve several related, more advanced problems such as atomic broadcast and atomic commit.
> 共识问题是许多商业分布式系统的核心问题。毕竟，我们想要的是分布式系统的可靠性和性能，而无需处理分布式的后果（如节点间的分歧/分歧），解决了共识问题，就有可能解决几个相关的、更高级的问题，如原子广播和原子提交。

### Two impossibility results
The first impossibility result, known as the FLP impossibility result, is an impossibility result that is particularly relevant to people who design distributed algorithms. The second - the CAP theorem - is a related result that is more relevant to practitioners; people who need to choose between different system designs but who are not directly concerned with the design of algorithms.
> 第一个不可能结果被称为 FLP 不可能结果，是一个与设计分布式算法的人特别相关的不可能结果。第二个不可能结果--CAP定理--是一个与实践者更相关的结果；实践者需要在不同的系统设计之间做出选择，但他们并不直接关注算法的设计。

## The FLP impossibility result
The FLP impossibility result (named after the authors, Fischer, Lynch and Patterson) examines the consensus problem under the asynchronous system model (technically, the agreement problem, which is a very weak form of the consensus problem). It is assumed that nodes can only fail by crashing; that the network is reliable, and that the typical timing assumptions of the asynchronous system model hold: e.g. there are no bounds on message delay.
> FLP 不可能性结果（以作者费舍尔、林奇和帕特森的名字命名）研究的是异步系统模型下的共识问题（严格来说是协议问题，是共识问题的一种非常弱的形式）。假设节点只能以崩溃的方式失败；网络是可靠的；异步系统模型的典型时序假设成立：例如，消息延迟不受约束。

Under these assumptions, the FLP result states that "there does not exist a (deterministic) algorithm for the consensus problem in an asynchronous system subject to failures, even if messages can never be lost, at most one process may fail, and it can only fail by crashing (stopping executing)".
> 在这些假设条件下，FLP 结果表明："在异步通信模型下，一个分布式系统中，即使只有一个进程可能会出现故障，也不存在一个完全正确的、确定性的算法来达成一致性"。

This result means that there is no way to solve the consensus problem under a very minimal system model in a way that cannot be delayed forever. The argument is that if such an algorithm existed, then one could devise an execution of that algorithm in which it would remain undecided ("bivalent") for an arbitrary amount of time by delaying message delivery - which is allowed in the asynchronous system model. Thus, such an algorithm cannot exist.
> 这一结果意味着，在一个极小的系统模型下，没有办法以一种不能永远延迟的方式来解决共识问题。我们的论点是，如果存在这样一种算法，那么我们就可以设计出一种算法的执行方式，通过延迟消息传递（这在异步系统模型中是允许的），在任意长的时间内保持未决（"二价"）。因此，这样的算法是不可能存在的。

This impossibility result is important because it highlights that assuming the asynchronous system model leads to a tradeoff: algorithms that solve the consensus problem must either give up safety or liveness when the guarantees regarding bounds on message delivery do not hold.
> 这一不可能性结果非常重要，因为它突出表明，假设采用异步系统模型会导致一种权衡：当有关消息传递界限的保证不成立时，解决共识问题的算法必须要么放弃安全性，要么放弃有效性。

This insight is particularly relevant to people who design algorithms, because it imposes a hard constraint on the problems that we know are solvable in the asynchronous system model. The CAP theorem is a related theorem that is more relevant to practitioners: it makes slightly different assumptions (network failures rather than node failures), and has more clear implications for practitioners choosing between system designs.
> 这一见解与设计算法的人员尤为相关，因为它对我们已知在异步系统模型中可以解决的问题施加了一个硬约束。CAP 定理是一个与实践者更相关的相关定理：它的假设略有不同（是网络故障而不是节点故障），对实践者选择系统设计有更明确的影响。

## The CAP theorem
The theorem states that of these three properties:
- Consistency: all nodes see the same data at the same time.
- Availability: node failures do not prevent survivors from continuing to operate.
- Partition tolerance: the system continues to operate despite message loss due to network and/or node failure
> 该定理指出，在这三个特性中：
	一致性：所有节点在同一时间看到相同的数据。
	可用性：节点故障不会妨碍幸存者继续运行。
	分区容忍性：尽管网络和/或节点故障导致信息丢失，系统仍能继续运行

only two can be satisfied simultaneously. We can even draw this as a pretty diagram, picking two properties out of three gives us three types of systems that correspond to different intersections:
> 只有两个可以同时满足。我们甚至可以把它画成一张漂亮的图，从三个属性中选出两个，就可以得到三种类型的系统，它们对应着不同的交叉点：
![[CAP.png]]

Note that the theorem states that the middle piece (having all three properties) is not achievable. Then we get three different system types:
- CA (consistency + availability). Examples include full strict quorum protocols, such as two-phase commit.
- CP (consistency + partition tolerance). Examples include majority quorum protocols in which minority partitions are unavailable such as Paxos.
- AP (availability + partition tolerance). Examples include protocols using conflict resolution, such as Dynamo.
> 请注意，该定理说明中间部分（具备所有三个属性）是无法实现的。这样，我们就得到了三种不同的系统类型：
	CA（一致性+可用性）。例如完全严格的法定人数协议，如两阶段提交。
	CP（一致性 + 分区容错）。例如 Paxos 等少数分区不可用的多数法定人数协议。
	AP（可用性 + 分区容错）。例子包括使用冲突解决的协议，如 Dynamo。

The CA and CP system designs both offer the same consistency model: strong consistency. The only difference is that a CA system cannot tolerate any node failures; a CP system can tolerate up to `f` faults given `2f+1` nodes in a non-Byzantine failure model (in other words, it can tolerate the failure of a minority `f` of the nodes as long as majority `f+1` stays up). The reason is simple:
- A CA system does not distinguish between node failures and network failures, and hence must stop accepting writes everywhere to avoid introducing divergence (multiple copies). It cannot tell whether a remote node is down, or whether just the network connection is down: so the only safe thing is to stop accepting writes.
- A CP system prevents divergence (e.g. maintains single-copy consistency) by forcing asymmetric behavior on the two sides of the partition. It only keeps the majority partition around, and requires the minority partition to become unavailable (e.g. stop accepting writes), which retains a degree of availability (the majority partition) and still ensures single-copy consistency.
> CA 和 CP 系统设计都提供相同的一致性模型：强一致性。唯一不同的是，CA 系统不能容忍任何节点故障；而 CP 系统在非拜占庭故障模型中，在 2f+1 个节点的情况下，最多可容忍 f 个故障（换句话说，只要多数 f+1 保持正常，它就能容忍少数 f 个节点的故障）。原因很简单：
	CA 系统无法区分节点故障和网络故障，因此必须停止接受任何地方的写入，以避免引入分歧（多副本）。它无法分辨是远程节点宕机，还是仅仅是网络连接宕机：因此唯一安全的办法就是停止接受写入。
	CP 系统通过强制分区两侧的非对称行为来防止分歧（例如，保持单副本一致性）。它只保留多数分区，而要求少数分区变得不可用（例如停止接受写入），这样就保留了一定程度的可用性（多数分区），并仍能确保单拷贝一致性。

